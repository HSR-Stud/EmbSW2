%!TEX root = ../EmbSW2.tex
\section{Advanced C++}

\subsection{Embedded Systems}
Embedded systems using C++ are diverse:
\begin{itemize}
	\item Real-time? Maybe.
	\item Safety-critcal? Maybe.
	\item Challenging memory limitations? Maybe.
	\item Challenging CPU limitations? Maybe.
	\item No heap? Maybe.
	\item No OS? Maybe.
	\item Multiple thread or tasks? Maybe.
	\item ''Old'' or ''weak'' compilers, etc.? Maybe.
	\item No hard drive? Often.
	\item Difficult to field-upgrade? Typically.
\end{itemize}

\subsubsection{Developing for Embedded Systems}
\begin{itemize}
	\item In general, little is ''special'' about developing for embedded systems:
	\begin{itemize}
		\item Software must respect the constraints of the problem and platform.
		\item C++ language features must be applied judiciously.
	\end{itemize}
	\item These are true for non-embedded applications, too.
	\begin{itemize}
		\item Good embedded software development is just good software development.
	\end{itemize}
\end{itemize}

\subsubsection{Implementing C++}
\begin{itemize}
	\item Why do you care?
	\begin{itemize}
		\item You're just curious: how do they do that?
		\item You're trying to figure out what's going on while debugging.
		\item You're concerned: do they do that efficiently enough?
		\begin{itemize}
			\item Our focus.
			\item Baseline: C size/speed
		\end{itemize}
	\end{itemize}
	\item Have faith:
	\begin{itemize}
		\item C++ was designed to be competitive in performance with C.
		\item Generally speaking, you don't pay for what you don't use.
	\end{itemize}
\end{itemize}

\subsection{Performance (Zeit und Codegrösse)}
\subsubsection{C++ vs. C}
\begin{itemize}
	\item No-Cost C++ features
		\begin{itemize}
			\item All the C stuff: structs, pointers, free functions, etc.
			\item Classes
			\item Namespaces
			\item Static functions and data
			\item Nonvirtual member functions
			\item Function and operator overloading
			\item Default parameters: Note that they are always passed. Poor design can thus be costly:
				\begin{lstlisting}
void doThat(const std::string& name = "Unnamed"); // Bad
const std::string defaultName = "Unnamed";
void doThat(const std::string& name = defaultName); // Better
				\end{lstlisting}
				Overloading can be a cheaper alternative. (Brauch aber mehr Code.)
			\item  Constructors and destructors: They contain code for mandatory initialization and finalization. However, they may yield chains of calls up the hierarchy.
			\item Single inheritance.
		\end{itemize}
	\item Low-Cost C++ features\\ You may pay for these features, even if you don't use them:
		\begin{itemize}
			\item Exceptions: a small speed and/or size penalty (code)\\
			When evaluating the cost of exceptions, be sure to do a fair comparison. Error handling costs you something, no matter how it is implemented.\\
			E.g., Saks reports object code increases of 15-40\% for error handling based on return values.
		\end{itemize}
	\item C++ features that can surprise inexperienced C++ programmers\\
	These \textbf{can} cost you if you're not careful:
		\begin{itemize}
			\item Temporary objects, e.g., returned from a+b:
			\begin{itemize}
				\item Many techniques exist to reduce the number and/or cost of such temporaries.
			\end{itemize}
			\item Templates
			\begin{itemize}
				\item Gefahr von Code Bloat
			\end{itemize}
		\end{itemize}
	\item Common Questions
	\begin{itemize}
		\item Why are simple ''hello world'' programs in C++ so big compared to C?
		\begin{itemize}
			\item iostream vs. stdio (bigger)
			\item ''hello world'' is an atypical program:
			\begin{itemize}
				\item For small programs, C++ programmers can still use stdio
				\item This improved a lot in the meantime (compilers and linkers are getting better)
			\end{itemize}
			\item Why do C developers moving to C++ often find their code is big and slow?
			\begin{itemize}
				\item C++ isn't C, and C programmers aren't C++ programmers
				\item C++ from good C++ developers as good as C from good C developers
			\end{itemize}
		\end{itemize}
	\end{itemize}
	\item Efficiency beyond C: C++ can be more efficient than C
	\begin{itemize}
		\item C++ feature implementation often better than C approximations:
		\begin{itemize}
			\item E.g., virtual functions
		\end{itemize}
		\item Abstraction + encapsulation $\rightarrow$ flexibility to improve implementations:
		\begin{itemize}
			\item std::strings often outperform char*-based strings:
			\begin{itemize}
				\item May use reference counting
				\item May employ ''the small string optimization''
			\end{itemize}
		\end{itemize}
		\item STL-proven techniques have revolutionized library design:
		\begin{itemize}
			\item Shift work from runtime to compile-time:
			\begin{itemize}
				\item Template metaprogramming (TMP), e.g., ''traits''
				\item Inlined operator(s)
			\end{itemize}
			\item Sample success story: C++'s sort() is faster than C's qsort()
		\end{itemize}
	\end{itemize}
	\item Vorteil von C++
    	\begin{itemize}
	        \item Abstraktion
	        \item Entkapselung
	        \item Inline Operationen
	        \item Shift work from runtime to compile-time
    	\end{itemize}
\end{itemize}

\subsubsection{Variable size}
\textbf{Hidden cost}\\
Using variables \textbf{larger} than the processor is comfortable with means extra loads/stores, extra computation (software routines versus hardware), of far slower instructions. This often ends up as calls, which does not add to size, but does significantly affect performance.\\
Using variables \textbf{smaller} than optimal may mean extra instructions to sign or unsign extend (on load and after computations). These may also prevent the use of optimal load and store instructions.\\
\\
\textbf{Cortex-M3}\\
Long long is generally optimized due to special instructions (for example, ADDC and UMULL). Smaller globals and statics are okay, but locals are best as ints and unsigned ints (or longs). If globals/static are used a lot, copy to int locals for duration, and copy back. It is not unusual to have a 40\% increase in function size due to use of short locals.\\
Beispiel:\vspace{-\baselineskip}
\begin{multicols}{2}
\lstinputlisting[language=C++]{code/variableSizeInt.cpp}
\vfill\null
\columnbreak
\lstinputlisting[language=C++]{code/variableSizeShort.cpp}
\end{multicols}

\subsubsection{Variablentypen}
\begin{itemize}
	\item int und unsigned int sind immer die effizientesten Datentypen
	\item Sie entsprechen der Registergrösse des jeweils verwendeten Prozessors
	\item Die Verwendung von short oder char spart deshalb kaum Speicher, ist jedoch üblicherweise deutlich langsamer als int
\end{itemize}

\subsubsection{Gewährleistung von Portabilität}
\begin{itemize}
	\item Ab C99 werden im Headerfile <inttypes.>, bzw. <stdint.h> verschiedene Typen mit genauer Breite definiert. Es ist deshalb sinnvoll, entweder genau diese Typen zu verwenden oder allenfalls diese mittels typedef zu definieren.
	\item Die Konventionen lauten wie folgt:\\
	\lstinline{intN_t}, wobei N = 8, 16, 32 für signed int-Typen\\
	Beispiele: \lstinline{in8_t, int16_t int32_t}\\
	\\
	\lstinline{uintN_t}, wobei N = 8, 16, 32 für unsigned int-Typen\\
	Beispiele: \lstinline{uint8_t, uint16_t, uint32_t}\\
	Ausschnitt aus $<$stdint.h$>$ von gcc:
\begin{lstlisting}[language=C++]
typedef signed char int8_t;
typedef short int16_t;
typedef long int32_t;
typedef long long int64_t;

typedef unsigned char uint8_t;
typedef unsigned short uint16_t;
typedef unsigned long uint32_t;
typedef unsigned long long uint64_t;
\end{lstlisting}
\item Weitere Typdefinitionen beinhalten effiziente Typen mit einer Mindestgrösse und schnelle Typen mit einer Mindestgrösse
\begin{lstlisting}
int_leastN_t
uint_leastN_t

inf_fastN_t
uint_fastN_t
\end{lstlisting}
\end{itemize}

\subsubsection{i++ oder ++i ?}
\begin{multicols}{2}
\lstinline{i++;} entspricht:
\begin{lstlisting}
{
  tmp = i;
  i += 1;
  "return" tmp;
}
\end{lstlisting}
\vfill\null
\lstinline{++i;} entspricht:
\begin{lstlisting}
{
  i +=1 ;
  "return" i;
}
\end{lstlisting}
\end{multicols}
Die Postfix-Operatoren bedingen im Prinzip ein tmp-Objekt. Gute Compiler werden das optimieren, schlechte jedoch nicht.

\subsubsection{Taking address of local variables}
\textbf{Hidden Cost}\\
Local variables are only allocated to the stack if they have to be. Keeping them in registers (and sharing a register between different ones not used at the same time) gives big gains in performance (that is, not having to do loads and stores). Taking the address of a local woll force it to the stack regardless of optimization level.\\
\\
\textbf{Cortex-M3}\\
All Cortex-M3 compilers support all-in-register locals when optimizations are turned on (size or speed).

\subsection{Inlining}
\begin{itemize}
	\item Vorteile
		\begin{itemize}
			\item Overhead von Funktionsaufrufen ist weg
			\item Schneller
			\item Branches verschwinden $\rightarrow$ pipeline- und cachefreundlich
			\item Für sehr kleine Funktionen kann sogar die Codegrösse kleiner werden
		\end{itemize}
	\item Nachteile
		\begin{itemize}
			\item Führt üblicherweise zu mehr Code
			\item Schwerer zu debuggen (Optimierung muss ausgeschaltet sein)
		\end{itemize}
	\item Beschränkungen
		\begin{itemize}
			\item Compiler kann inlining ignorieren
			\item Funktionen, auf die ein Pointer zeigt, werden nicht inlined
			\item Virtuelle Funktionen werden kaum inlined (inline: compile-time, virtual: run-time)
			\item ''Komplizierte'' Funktionen ebenfalls nicht (der jeweilige Compiler entscheidet, was ''kompliziert'' ist)
			\item Rekursive Funktionen werden nie inlined
			\item (Ältere) Linker können kaum Inlining,d.h. die inline-Funktionen sollten bereits dem Compiler vollständig bekannt sein. Dies kann erreicht werden, indem die Inline-Funktionen direkt im Header definiert werden.
		\end{itemize}
\end{itemize}

\subsubsection{Normal Inlining}
\begin{itemize}
	\item Inline functions are defined in headers
	\item .cpp files know the function definition by including the header $\rightarrow$ compiler can inline this function
\end{itemize}

\subsubsection{Automatic Inlining}
\begin{multicols}{2}
Compilers may inline functions not declared inline, but this is uncommon.
\begin{itemize}
	\item To inline a function, compilers need its definition, but non-inline functions are not defined in header files.
	\item They'd cause duplicate symbol errors during linking
	\item Non-inline functions are thus declared in headers, not defined there.
	\item The rules for function templates are a bit different...
\end{itemize}
\vfill\null
\columnbreak
\includegraphics[width=\linewidth]{images/AdvancedCPP/automaticInline}
\end{multicols}
\begin{multicols}{2}
Compilers rarely inline functions only declared in headers.
\begin{itemize}
	\item They need to know the function body to inline it.
	\item When they do know it, inlining is easy (and common).
\end{itemize}
\vfill\null
\columnbreak
\includegraphics[width=\linewidth]{images/AdvancedCPP/automaticInline2}
\end{multicols}

\subsubsection{Link-Time Inlining}
\begin{itemize}
	\item Linkers are not allowed to perform inlining:
	\begin{itemize}
		\item Many already do when \textbf{Whole Program Optimization (WPO)}, aka \textbf{Link-Time Optimization (LTO)}, is on, e.g. GNU, Microsoft, Intel, Sun
	\end{itemize}
	\item Merely eliminating calls/returns during linking isn't enough.
	\begin{itemize}
		\item Full benefit requires post-inlining flow analysis.
		\begin{itemize}
			\item Hence the need for WPO, aka LTO above.
		\end{itemize}
	\end{itemize}
	\item Still, manual inline declarations remain a necessary evil.
\end{itemize}
\textbf{Bottom Line:}\\
\begin{itemize}
	\item Inlining is almost always a good bet for small, frequently called functions.
	\begin{itemize}
		\item Overall runtime speed is likely to increase.
	\end{itemize}
	\item Imprudent inlining can lead to code bloat.
	\item Minimize inlining if binary upgradeability is important.
\end{itemize}

%TODO: SW8 hier weitermachen



\subsection{Static vs. Dynamic Binding}
\begin{itemize}
	\item Static binding (early binding, statische Bindung)
		\begin{itemize}
			\item Bereits zur Compilezeit wird festgelegt, welcher (Elementfunktions-) Code
				ausgeführt wird (Normalfall)
			\item ''Normale`` Klassen, templates
		\end{itemize}
	\item Dynamic binding (late binding, dynamische Bindung)
		\begin{itemize}
			\item Erst zur Laufzeit wird in Abhängigkeit des Objekts festgelegt, welcher
				(Elementfunktions-) Code ausgeführt wird
			\item Run-Time Polymorphismus, virtual
			\item Laufzeit mehraufwand, weniger effizient
		\end{itemize}
\end{itemize}

\subsubsection{Virtuelle Memberfunktionen (Siehe Zf\_OOProg)}
Soll die Funktion überschrieben werden können, muss \emph{virtual} verwendet werden.
Wird virtual nicht verwendet, wird die Funktion nur ''versteckt``.
\lstinputlisting{code/virttest.cpp}


\subsection[RAII]{RAII - RESOURCE ACQUISITION IS INITIALISATION}

\paragraph{Motivation}
Resourcen (Datei, Speicher, Semaphoren) müssen vor Gebrauch angefordert und danach wieder freigegeben werden.
Dazwischen könnte aber z.B. eine Exception auftreten, was das Freigeben verhindert.

\paragraph{Lösung}
Damit die Resource trotzdem freigegeben wird, kann sie als Klassen-Objekt instanziert werden. Das Objekt wird automatisch gelöscht wenn es seine Gültigkeit (out-of-scope) verliert.
\begin{compactitem}
	\item Konstruktor fordert die Resource an
	\item Destruktor gibt sie wieder frei
\end{compactitem}


\paragraph{Heap-Objekte}
Für Heap-Objekte stellt die Boost-Library Templates für diesen Zweck zur Verfügung.\\
Problem:
\begin{lstlisting}
void f()
{
	Person* p = new Person("irgendwer");
	// mach etwas mit p
	// was ist, wenn vorher eine Exception geworfen wird?
	delete p;
}
\end{lstlisting}

Lösung:
\begin{lstlisting}
void f()
{
	boost::shared_ptr<Person> p(new Person("irgendwer"));
	// mach etwas mit p
	// Beim Verlassen des Blocks räumt Destruktor von shared_ptr
	// automatisch auf und löscht die Person
}
\end{lstlisting}


\paragraph{Semaphoren} Für Semaphoren könnte die folgende Implementierung verwendet werden


\begin{lstlisting}
class Semaphore
{
public:
	Semaphore(int s=0): id(s) {getSem(s);}
	~Semaphore() {releaseSem(id);}
private:
	int id;
};
\end{lstlisting}
\begin{lstlisting}
void f()
{
  // kritischer Abschnitt
  {
    Semaphore myS;
  } // hier wird Semaphore freigegeben, Destruktor wird aufgerufen
}
\end{lstlisting}


\subsection[pImpl]{pImpl - \textcolor{red}{P}ointer to \textcolor{red}{Impl}ementation}
\label{sec:pimpl}

\paragraph{Problem} Wie kann man die Implementierung einer Klasse so verstecken, dass man sie
ändern kann, ohne alle Module, welche die Klasse nutzen, bei einer Änderung
neu übersetzen zu müssen?
Nützlich zum Beispiel für eine shared library / DLL.

\paragraph{Lösung}
\begin{itemize}
\item Implementierung im .cpp File wird in einem separatem File versteckt
\item Im Header nur noch die öffentliche Schnittstelle mit einem Pointer auf die Implementierung
\item Die Implementation wird auf dem Heap angelegt $\rightarrow$ unproblematisch weil diese Objekt beim Programmstart angelegt und erst am Schluss wieder freigegeben wird
\end{itemize}

\begin{lstlisting}
#ifndef HIDDENCOUNTER_H_ // public file
#define HIDDENCOUNTER_H_
#include <boost/shared_ptr.hpp>
class HiddenCounter
{
public:
	HiddenCounter(int i=0);
	void inc();
	int count() const;
	void reset();
private:
	boost::shared_ptr<class CounterImpl> pImpl;
};
#endif // HIDDENCOUNTER_H_

#include "HiddenCounter.h" // private file
class CounterImpl
{
public:
	CounterImpl(int i): counter(i) {}
	void inc() { ++counter; }
	int count() const { return counter;}
	void reset() { counter=0; }
private:
	int counter;
};
HiddenCounter::HiddenCounter(int i)
:pImpl(new CounterImpl(i)) {}
void HiddenCounter::inc() {pImpl->inc();}
int HiddenCounter::count() const
	{ return pImpl->count(); }
void HiddenCounter::reset() {pImpl->reset();}
\end{lstlisting}






\subsection{Polymorphismus}
\begin{itemize}
	\item Runtime
		\begin{itemize}
			\item Vererbung, virtuelle Funktionen
			\item Am flexibelsten, kann Informationen verwenden die erst zur Laufzeit bekannt sind
			\item Teurer Laufzeitaufwand, vptrs, vtpls, alles non-inline
		\end{itemize}
	\item Link-Time
		\begin{itemize}
			\item Separat kompilierte Funktionen mit gleicher Definition (gleicher Header) (z.B.
				Hardware abhängiger Code)
			\item Statisches oder dynamisches linken, siehe auch \nameref{sec:pimpl}
			\item Je nach Software Anwendung, können z.B. noch Treiber dazugelinkt werden
		\end{itemize}
	\item Compile-Time
		\begin{itemize}
			\item typedefs um Klasse zu wählen, Templates, \#ifdef's, const expressions
			\item z.B. Rechnerarchitektur (32Bit, 16Bit) erst bekannt zur Compile Zeit
		\end{itemize}
\end{itemize}
\begin{lstlisting}
template<int ptrBitsVs32> struct DeviceChoice;
template<> struct DeviceChoice<-1> { // When bits/ptr < 32
typedef SASDevice type;
};
...
struct Device {
    enum { bitsPerVoidPtr = CHAR_BIT * sizeof(void*) };
    enum { ptrBitsVs32 = bitsPerVoidPtr > 32 ? 1 :  // Condition ? Condition true : Condition false;
           bitsPerVoidPtr == 32 ? 0 : -1        //Nur Kurzform von if/else funktioniert in enum
};
typedef DeviceChoice<ptrBitsVs32>::type type;
};
\end{lstlisting}

\subsection{Avoiding Code-Bloat / Templates}
\subsubsection{Allgemein}
Um so wenig wie Möglich Code-Bloat zu verursachen sollte folgende beachtet werden.
\begin{compactitem}
    \item Exception nur wenn zwingend nötig ist gebrauchen
    \item stdio anstatt iostreams verwenden
    \item Excessive inline verhindern, speziell mit Templates beachten
    \item Explizit überlegt instanzieren (Gemeinsamkeiten in die Basisklasse auslagern)
    \item Code hoisting bei unabhängigen Template Parametern
\end{compactitem}

\subsubsection{Templates}
Bei Template Klassen werden nur die benötigten Funktionen instanziert. Das hat zur Folge das kein Code und keine Daten verbraucht werden. Bei Sicherheitskritischen Systemen wird zudem verlangt das kein Dead-Code vorhanden ist, was mit Templates verhindert werden kann. Templates sind normalerweise im Header definiert, sie werden aber nicht automatisch als inline instanziert. Explizites Inlinen sollte bei Templates vermieden werden, weil dies zu Code-Bloat führt\\

Die Template instanzierung im Header bringt folgende Vorteile
\begin{compactitem}
    \item Es muss nur das Header File angepasst werden
    \item der Client kann Änderungen vornehmen
    \item Template kann implizit instanziert werden
    \item Verhinderung von ugly-Include
\end{compactitem}

Nachteile:
\begin{compactitem}
    \item Kompilierzeit erhöht
    \item Weil die Templates im Header sind wird auch die Kompilierzeit des Clients erhöht
\end{compactitem}


\begin{lstlisting}
// .h File
template<typename T>
class SomeClass {
  public:
    SomeClass() { ... } // implizit inline
    void mf1() { ... }  // implizit inline
    void mf2();         // nicht implizit inline
    ...
};
template<typename T>
void SomeClass<T>::mf2() { ... } // im Header definiert, aber nicht inline
\end{lstlisting}


\paragraph{Templates explizit instanzieren}~
\\
Die Templates kann man auch explizit Instanzieren. Bei expliziter Instanzierung muss man aber manuell jedes Template machen.\\

Dies ist nützlich um:
\begin{compactitem}
	\item Eine Bibliothek von Instanzen zu erstellen
	\item Um Code-Bloat von schlechten Compilern / Linkern zu vermeiden, welche immer alle Funktionen einer Template-Klasse instanzieren.
	\item Um Templates in bestimmten Code Section zu instanzieren
\end{compactitem}~\\

Zusätzliches .cpp File um die mf2() Funktion explizit zu instanzieren.
\begin{lstlisting}
// .cpp File
... // Definitionen der nicht-inline Funktionen von SomeClass

template
class SomeClass<double>; // Explizite Instanzierung von allen SomeClass
                         // Funktionen mit T=double; der kompilierte
                         // Code kommt ins .obj File von diesem cpp
template
void SomeClass<int>::mf2(); // Explizite Instanzierung von SomeClass::mf2
                             // mit T=int; kompilierter code ebenfalls im .obj File
\end{lstlisting}

Die Ausführbare Datei (.exe) kann mit mehreren Kopien von einer Template Instanz enthalten.
\begin{compactitem}
    \item Wenn der Kompiler auch Funktionen instanziert, welche nicht benötigt werden
    \item Wenn man dynamisch Linked
    \item Wenn einen schlechten Linker verwendet
\end{compactitem}

\paragraph{Code Duplizierung Vermeiden / Code Hoisting} (siehe Praktikum 11)
\\
Typunabhängiger Code erzeugt zusätlichen Code-Bloat
\begin{lstlisting}
template<typename T, std::size_t BUFSZ> // Suspect design: each
class Buffer {                          // BUFSZ value will yield a
T buffer[BUFSZ];                        // new set of member functions
public:
...
};
\end{lstlisting}

\begin{minipage}{15cm}
Verbesserte Variante (typunabhängiger Code in der Basisklasse)
\begin{lstlisting}
template<typename T>
class BufferBase { // Better design: BufferBase
...                // is independent of BUFSZ
};
template<typename T, std::size_t BUFSZ> // Buffer does only BUFSZ-
class Buffer: public BufferBase<T> {    // dependent operations.
...                                     // Ideally, all are inline, so
};                                      // Buffer classes cost nothing
\end{lstlisting}
\end{minipage}~
\begin{minipage}{3cm}
\tikzstyle{myarrow}=[->, >=open triangle 90]
\begin{tikzpicture}
    \hspace{0.5cm}
    \draw (0,1) rectangle (3,1.5) node[pos=.5] {BufferBase};
    \draw (0,0) rectangle (3,1.5) ;


    \draw (0,3) rectangle (3,4) node[pos=.5] {Buffer};
    \draw (0,2.5) rectangle (3,4);

    \draw [myarrow] (1.5,1.5) -- (1.5,2.5);


 \end{tikzpicture}
\end{minipage}

\subsection{Interface Programming}


\begin{minipage}{11cm}
\begin{lstlisting}
class Packet { // base class (interface)
public:
...
virtual bool isWellFormed() const = 0 //=0 =>abstrakt;
virtual std::string payload() const = 0;
...
};
class TCPPacket: public Packet { // derived class (implementation)
...
virtual bool isWellFormed() const;
virtual std::string payload() const;
...
};
class CANPacket: public Packet { // derived class (implementation)
...
virtual bool isWellFormed() const;
virtual std::string payload() const;
...
};
\end{lstlisting}
\end{minipage}~
\begin{minipage}{9cm}
\tikzstyle{myarrow}=[->, >=open triangle 90]
\begin{tikzpicture}
    \hspace{1cm}
    \draw (1.5,1.5) rectangle (4.5,2) node[pos=.5] {CANPacket};
    \draw (1.5,0) rectangle (4.5,2) ;

    \draw (5.5,1.5) rectangle (8.5,2) node[pos=.5] {TCPPacket};
    \draw (5.5,0) rectangle (8.5,2) ;

    \draw (3.5,5.5) rectangle (6.5,6) node[pos=.5] {\textit{Packet}\{abstract\}};
    \draw (3.5,4) rectangle (6.5,6);

    \draw [myarrow] (3,2) -- (4.5,4);
    \draw [myarrow] (7,2) -- (5.5,4);

 \end{tikzpicture}
\end{minipage}




\subsection{Dynamic Memory Managment (DMM)}
Die vier Sorgen:\\
\begin{tabular}{p{12cm}p{5cm}}

\vspace{-2cm}
\begin{itemize}
\item Schnelligkeit: Sind \textbf{new/delete/malloc/free} schnell genug?
\item Fragmentierung: Entstehen im Heap unbrauchbar kleine Bereiche?
\item Speicherlecks: Werden einige Bereiche nicht frei gegeben?
\item Speicherersch"opfung: Wird eine Allokation nicht gemacht?

\end{itemize}
&

\begin{minipage}{5cm}
\begin{tikzpicture}
    \draw (0, 0) rectangle (5, 3) ;
    \draw (0, -0.7) rectangle (2, -0.2) node[pos=.5] {frei};
    \filldraw[fill=green!20!white, draw=green!40!black] (3, -0.7) rectangle (5, -0.2) node[pos=.5] {besetzt};
    \filldraw[fill=green!20!white, draw=green!40!black] (0,0) rectangle (1,0.5);
    \filldraw[fill=green!20!white, draw=green!40!black] (2,0) rectangle (5,0.5);
    \filldraw[fill=green!20!white, draw=green!40!black] (0,0.5) rectangle (2,1);
    \filldraw[fill=green!20!white, draw=green!40!black] (2.5,0.5) rectangle (5,1);
    \filldraw[fill=green!20!white, draw=green!40!black] (0.5,1) rectangle (3,1.5);
    \filldraw[fill=green!20!white, draw=green!40!black] (4.5,1) rectangle (5,1.5);
    \filldraw[fill=green!20!white, draw=green!40!black] (0,1.5) rectangle (5,2);
    \filldraw[fill=green!20!white, draw=green!40!black] (0,2) rectangle (0.3,2.5);
    \filldraw[fill=green!20!white, draw=green!40!black] (0.5,2) rectangle (1,2.5);
    \filldraw[fill=green!20!white, draw=green!40!black] (1.5,2) rectangle (2,2.5);
    \filldraw[fill=green!20!white, draw=green!40!black] (2.5,2) rectangle (3,2.5);
    \filldraw[fill=green!20!white, draw=green!40!black] (4,2) rectangle (5,2.5);
    \filldraw[fill=green!20!white, draw=green!40!black] (0.3,2.5) rectangle (4.7,3);
\end{tikzpicture}
 \end{minipage}\\


% Fragmentierungsproblem:\\
% \multicolumn{2}{l}{
%     \begin{minipage}
%     \begin{itemize}
%         \item tritt auf wenn während der Laufzeit new/delete gemacht wird
%         \item kann verhindert werden wenn nur beim Heruntefahren delete gemacht wird
%         \item die Speicherbeschreibung wird langsam, weil beim erneuten allozieren, zuerst ein Speicherbereich gesucht werden muss, welcher gross genug ist
%         \item es können unbrauchbare kleine Speicherbereiche entstehen
%     \end{itemize}
%     \end{minipage}
%}

\end{tabular}

Fragmentierungsproblem:
\begin{itemize}
    \item tritt auf wenn während der Laufzeit new/delete gemacht wird
    \item kann verhindert werden wenn nur beim Heruntefahren delete gemacht wird
    \item die Speicherbeschreibung wird langsam, weil beim erneuten allozieren, zuerst ein Speicherbereich gesucht werden muss, welcher gross genug ist
    \item es können unbrauchbare kleine Speicherbereiche entstehen
\end{itemize}





% \begin{compactitem}
% \item Fully Static Allocation
% \item LIFO Allocation
% \item Pool Allocation
% \item Block Allocation
% \item Region Allocation
% \end{compactitem}
\paragraph{Allocation Strategies: }~\\
\begin{tabular}{l||p{7cm}|p{7cm}|}
                        &  Fully Static Allocation & LIFO Heap Allocation\\
    \hline \hline
                        &   Daten nicht auf dem Heap $\rightarrow$ Exakte bzw. max. Anzahl der Objekte ist determinierbar. & Dynamische Allokation ausserhalb des runtime Stacks $\rightarrow$ Diese Allokationen sind immer LIFO (wie beim Stack)\\
    Speed               &   praktisch unendlich, deterministisch    & Sehr schnell, deterministisch \\
    Fragmentation       &   Nicht m"oglich                          & M"oglich, einfach zu erkennen\\
    Memory leaks        &   Nicht m"oglich                          & M"oglich, einfach zu erkennen\\
    Memory exhaustion   &   Nicht m"oglich                          & M"oglich\\



\end{tabular}

\vspace{1cm}

\begin{tabular}{l||p{7cm}|p{7cm}|}
                        &  Pool Allocation & Block Allocation\\
    \hline \hline
                        & Pool Allokationen sind \textbf{alle gleich gross} (bzw. alle so gross, wie das gr"osste Element)

                        &   Verschiedene Sets von Pools mit verschiedenen Gr"ossen
                        \newline
                        \begin{tikzpicture}
                            \draw (0, 0) rectangle (1.5, 0.5) node[pos=.5] {Pool 1};
                            \draw (1.5, 0) rectangle (5, 0.5) node[pos=.5] {Pool 2};
                            \draw (0, 0) rectangle (5, -0.5) node[pos=.5] {Pool 3};
                        \end{tikzpicture}\\
    Speed               &   Sehr schnell, deterministisch       & Schnell, praktisch deterministisch  \\
    Fragmentation       &   Nicht m"oglich                      & Nicht m"oglich\\
    Memory leaks        &   M"oglich                            & M"oglich, einfach zu erkennen\\
    Memory exhaustion   &   M"oglich                            & M"oglich\\



\end{tabular}
\\
% Fully Static Allocation:
% \begin{itemize}
% \item Daten nicht auf dem Heap $\rightarrow$ Exakte bzw. max. Anzahl der Objekte ist determinierbar.
% \item \textbf{Speed}: praktisch unendlich, deterministisch
% \item \textbf{Fragmentation}: Nicht m"oglich
% \item \textbf{Memory leaks}: Nicht m"oglich
% \item \textbf{Memory exhaustion}: Nicht m"oglich
% \end{itemize}

% LIFO Heap Allocation:
% \begin{itemize}
% \item Dynamische Allokation ausserhalb des runtime Stacks $\rightarrow$ Diese Allokationen sind immer LIFO (wie beim Stack)
% \item \textbf{Speed}: Sehr schnell, deterministisch
% \item \textbf{Fragmentation}: M"oglich, einfach zu erkennen
% \item \textbf{Memory leaks}: M"oglich, einfach zu erkennen
% \item \textbf{Memory exhaustion}: M"oglich
% \end{itemize}

% Pool Allocation:
% \begin{itemize}
% \item Heap Allokationen sind \textbf{alle gleich gross} (bzw. alle so gross, wie das gr"osste Element)
% \item \textbf{Speed}: Sehr schnell, deterministisch
% \item \textbf{Fragmentation}: Nicht m"oglich
% \item \textbf{Memory leaks}: M"oglich
% \item \textbf{Memory exhaustion}: M"oglich
% \end{itemize}

% Block Allocation:
% \begin{itemize}
% \item Verschiedene Sets von Pools mit verschiedenen Gr"ossen
% \item \textbf{Speed}: Schnell, praktisch deterministisch
% \item \textbf{Fragmentation}: Nicht m"oglich
% \item \textbf{Memory leaks}: M"oglich
% \item \textbf{Memory exhaustion}: M"oglich
% \end{itemize}

\textbf{Region Allocation:} N"utzlich wenn alle Heapobjekte simultan frei gegeben werden.
\subsection{POD (Plain Old Data)}
Folgende sind POD
\begin{itemize}
 \item alle C Datentypen (int, float, uws.)
 \item c++11 Klassen, Unions, Structs wenn folgendes nicht enthalten
 \begin{itemize}
     \item Basisklassen
     \item Virtual Funktion
     \item Non-static data mebemrs of refence type (int\& a;)
     \item Non-static data members of non-POD(z.B. virtuelle Klasse) ( types (int a;)
 \end{itemize}
\end{itemize}
POD Typen in C++98/03 ist strikter, weil private und protected data members ausgeschlossen sind. Mit private und protected kann man das ROMable verhindern.

\subsection{C++ and ROM}
Folgendes ist ROMable:
\begin{compactitem}


\item POD Type
\item Wert ist vor Laufzeit bekannt
\item Wert kann zur Laufzeit nicht modifiziert werden
\item Warum sind Konstanten mit \#define schlecht?
	\begin{compactitem}
		\item Sie respektieren den Scope nicht
		\item weder private noch protected
		\item kein Typ
	\end{compactitem}
	$\rightarrow$ Besser mit const. Oder noch besser mit enum (negative Zahlen auch möglich)
\item Werden geROMt, wenn: Als const definiert, wenn sie keine mutierenden
	Daten enthalten, Wenn sie mit bekannten Werten initialisiert werden
	w"ahrend der Kompilation.
\end{compactitem}

\subsection{Schlüsselwörter und Speicher}  (Praktikum 12)
Konstanten\\
\begin{tabular}{l|l}
\hline
   \#define  & + Bei nicht Verwendug entsteht weder Code noch Daten\\
             & - keine Typenprüfung, Makroprobleme\\
             & pro Kompilationseinheit wird eine Speicherplatz benötigt für die Konstante \\ \hline
    const    & - Erzeugt auch Code und Daten wenn auch nicht gebraucht\\
             & Konstante wird nur einmal pro Projekt erzeugt\\\hline
    enum     & + Bei nicht Verwendug entsteht weder Code noch Daten\\
             & auch negative Zahlen\\\hline
\end{tabular}

\begin{lstlisting}
const char* pc1 = "Hello World"; // "Hello World" is ROMable (but pc1 is not)
const char* const pc2 = "World"; // "World" is ROMable (and may be shared with  "Hello World") pc2 is also ROMable
\end{lstlisting}
Für Integer Konstanten sollte immer enum verwendet werden. Für Double Konstanten wird empfohlen die const Variante zu wählen.\\

\begin{tabular}{l|l}
\hline
   static   & Variablen, Arrays werden auf in den Datenbereich gespeichert, nicht auf dem Stack\\
            & Variablen ausserhalb von Funktionen, sind File Globale\\
            & Variablen innerhalb von Funktionen, werden das erste Mal mit Null initialisiert\\
            &  Behalten den Wert auch wenn Out-Of-Scope\\ \hline
    const   & Daten werden ins Rom geschrieben \\
    vtbl's  & werden in den Read Only Bereich gespeichert (ROM)
\end{tabular}\\




\subsection{Modeling Memory-Mapped I/O}
Viele Systeme haben ihre I/O (\textit{memory-mapped IO devices}) im Programm-Adressbereich.
Mit C++ ist es einfach diese \textit{memory-mapped IO devices} mithilfe von Objekten anzusteuern.

\begin{tabular}{|p{9.2cm}|p{9.2cm}|}
    \hline
    Placement new   &   Ras Casts\\
    \hline \hline
    + Konstruktor wird automatisch aufgerufen & - Konstroktur muss zusätzlich aufgerufen werden \\
    - Kann zusätzlichen Overhead generieren (Kompiler abhängig) & Keinen Overhead\\ \hline
\end{tabular}

\vspace{0.5cm}

\begin{tabular}{|p{9.2cm}|p{9.2cm}|}
    \hline
    Compiler Extension     &   Linker Commands \\
    \hline\hline
    - Nicht Portabel & + Besser Portabel als Compiler Extension (Platform spezifische Adressen sind im Linkerskript vorhanden) \\
    + Kein Pointer \newline ($\rightarrow$ kein benötigter Speicher für den Pointer) & Mangled Names werden verwendet\\
    \hline
\end{tabular}

\paragraph{Modeling Memory-Mapped IO}
\begin{itemize}
	\item Atomic reads/writes may require explicit synchronization.
	\item Individual bits may sometimes be read-only, other times write-only.
	\item Clearing a bit may require assigning a 1 to it.
	\item One status register may control more than one data register.
		E.g., bits 0-3 are for one data register, bits 4-7 for another.
\end{itemize}

\paragraph{Modeling a Control Register}~
\begin{lstlisting}
enum { bit0 = 0x1, bit1 = 0x2, ... , bit31 = 0x80000000 };

class ControlReg {
public:
	bool ready() const 	{ return regValue & bit0; }
	bool interruptsEnabled() const { return regValue & bit2; }
	void enableInterrupts() { regValue |= bit2; }
	void disableInterrupts(){ regValue &= ~bit2; }
private:
	volatile unsigned regValue;		// data in the register may change
									// outside program control
};
\end{lstlisting}

All functions are inline, so their existence should incur no cost.

\paragraph{Placement new vs. Raw Casts}~\\
\emph{Placement new} wird normalerweise dem \emph{raw} \texttt{reinterpret\_cast} Vorgezogen, \emph{placement new} den Konstruktor aufruft, was mit \texttt{reinterpret\_cast} selber gemacht werden müsste:
\begin{lstlisting}
pcr->ControlReg();
\end{lstlisting}

\paragraph{Placement new}~\\
Operator new’s fundamental job is not to allocate memory, it’s to identify where an object should go.

\begin{itemize}
	\item You can pass operator new where you want to put something, and it will return that location
	\item This form of operator new is called placement new.
			It’s a standard form available everywhere.
\end{itemize}

Beispiel mit Pointer:
\begin{lstlisting}
ControlReg * const pcr = new (reinterpret_cast<void*>(0xFFFF0000)) ControlReg;

while (!pcr->ready()) ; 			// wait until the ready bit is on
pcr->enableInterrupts(); 			// enable device interrupts
if (pcr->interruptsEnabled())... 	// if interrupts are enabled...

\end{lstlisting}

Beispiel mit Referenz:
\begin{lstlisting}
ControlReg& cr = *new (reinterpret_cast<void*>(0xFFFF0000)) ControlReg;

while (!cr.ready()) ; 				// wait until the ready bit is on
cr.enableInterrupts(); 				// enable device interrupts
if (cr.interruptsEnabled()) ... 	// if interrupts are enabled...
\end{lstlisting}
~ \\
Mit \textit{placement new} wird kein Speicher alloziert, somit darf auch kein delete ausgeführt werden.
\begin{lstlisting}
    int * a = new int[10];          //Speicher Allozierung
    delete[] a;                     //Heap wird gelöscht wichtig delete[] für Array

    int * b = new (0xFFFF0000) int; //Placement new an der Adressse 0xFFFF0000
    delete b;                       //!!ERROR, Keine Delete beim Placement new
\end{lstlisting}

\paragraph{Raw Casts}~
\begin{lstlisting}
ControlReg *pcr = reinterpret_cast<ControlReg*>(0xFFFF0000);	// pointer version

ControlReg& cr = *reinterpret_cast<ControlReg*>(0xFFFF0000);	// reference version
\end{lstlisting}



\paragraph{Direkt vs Indirekt}~
\\
\vspace{0.5cm}
\begin{tabular}{|p{9.2cm}|p{9.2cm}|}
    \hline
    Direkt   &   Indirekt\\
    \hline \hline
    Enthalten nur statische Daten & Objekte nicht an eine spezifische Adresse gebunden (wird vom Client mit Template oder mit einem Konstruktor Argument definiert\\
    Enthalten nie virtuelle Funktionen & Kann zusätzliche Daten Member enthalten\\
    Schneller als Indirekt& Benötigt zusätzlichen Speicher (Pointer)\\
    & Flexibler als direkt\\
    \hline
\end{tabular}



\paragraph{Direkt}~
\\
\begin{tabular}{|p{9.2cm}|p{9.2cm}|}

\begin{lstlisting}
class OutputDevice3
{
  public:
    ControlReg& control() {return cr;}
    void write(uint32_t value) {data = value;}
  private:
    OutputDevice3(const OutputDevice3&); // prevent copying
    ControlReg cr;
    volatile uint32_t data;
};
\end{lstlisting}
&
Client
\begin{lstlisting}
// create OutputDevice3 object at address 0xFFFF0000
OutputDevice3& od =
*new (reinterpret_cast<void*>(0xFFFF0000)) OutputDevice3;
\end{lstlisting}
\end{tabular}

\paragraph{Indirekt}~
\\
\begin{tabular}{|p{9.2cm}|p{9.2cm}|}
\begin{lstlisting}
class OutputDevice1
{
  ...
  private:
    ControlReg* const pcr; // data members that do not map
    volatile uint32_t* const pd; // to MMIO device registers
    uint32_t lastValueWritten; // useful for write-only regs
};
\end{lstlisting}
&
Client

\\
\hline
\begin{lstlisting}
class DeviceBase {
  public:
    virtual void reset() = 0;
    ...
};

class OutputDevice1: public DeviceBase {
  public:
    virtual void reset();
    ...
};

template<uint32_t controlAddr, uint32_t dataAddr>
class OutputDevice2: public DeviceBase {
public:
virtual void reset();
...
};
\end{lstlisting}
&
\begin{lstlisting}
OutputDevice1 od1a(0xFFFF0000, 0xFFFF0004);
OutputDevice1 od1b(0xFFFF0010, 0xFFFF0014);
...
OutputDevice2<0xEEEE0000, 0xEEEE0010> od2a;
OutputDevice2<0xEEEE0020, 0xEEEE0040> od2b;
...
DeviceBase* registers[] = {&od1a, &od1b, ..., &od2a, &od2b, ...};
const std::size_t numRegisters =
sizeof(registers)/sizeof(registers[0]);
...
for (std::size_t i = 0; i < numRegisters; ++i)
{ // reset all registers in system
  registers[i]->reset();
}
\end{lstlisting}
\end{tabular}

\paragraph{Preventing Client Errors}~

\begin{tabular}{|p{9.2cm}|p{9.2cm}|}
\begin{lstlisting}
// class modeling hardware directly
class OutputDevice3
{ // prevents some kinds of client errors
  ...
  private:
    ~OutputDevice3() {}
    ControlReg cr;
    volatile uint32_t data;
};
\end{lstlisting}
&
\begin{lstlisting}
OutputDevice3 d;
// error! implicit destructor invocation.
// (We want to prevent MMIO objects from
// being placed on the stack.)

OutputDevice3* pd =
new (reinterpret_cast<void*>(0xFFFF0000)) OutputDevice3; // fine
...
delete pd; // error! another implicit destructor invocation
\end{lstlisting}
\end{tabular}
